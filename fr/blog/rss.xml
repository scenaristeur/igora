<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Igora Protocol Blog</title>
        <link>https://scenaristeur.github.io/igora/fr/blog</link>
        <description>Igora Protocol Blog</description>
        <lastBuildDate>Mon, 29 Apr 2024 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>fr</language>
        <item>
            <title><![CDATA[Pour bien démarrer avec les LLM !]]></title>
            <link>https://scenaristeur.github.io/igora/fr/blog/Pour bien démarrer avec les LLM !</link>
            <guid>https://scenaristeur.github.io/igora/fr/blog/Pour bien démarrer avec les LLM !</guid>
            <pubDate>Mon, 29 Apr 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Pour bien comprendre de quoi on parle quand il est question d'Intelligence Artificielle Générative]]></description>
            <content:encoded><![CDATA[<p>Pour bien comprendre de quoi on parle quand il est question d'<strong>Intelligence Artificielle Générative</strong>
et pour appréhender au mieux les LLM (Large Modèle de Langage), nous allons procéder en 3 étapes
que vous pouvez suivre sur <a href="https://colab.research.google.com/github/scenaristeur/igora/blob/main/notebooks/llama_cpp_python_fr.ipynb" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="img_ev3q"></a></p>
<blockquote>
<p>sur google colab, les commandes "système" sont précédées par un point d'exclamation.</p>
</blockquote>
<ul>
<li>1 Téléchargement d'un modèle de langage (dolphin)</li>
<li>2 Installation d'un moteur d'inférence (llama-cpp-python)</li>
<li>3 Interrogation du modèle de langage via le moteur d'inférence (Nomme les planètes du système solaire)</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-t�éléchargement-dun-modèle-de-langage-dolphin">1 Téléchargement d'un modèle de langage (dolphin)<a href="https://scenaristeur.github.io/igora/fr/blog/Pour%20bien%20d%C3%A9marrer%20avec%20les%20LLM%20!#1-t%C3%A9l%C3%A9chargement-dun-mod%C3%A8le-de-langage-dolphin" class="hash-link" aria-label="Lien direct vers 1 Téléchargement d'un modèle de langage (dolphin)" title="Lien direct vers 1 Téléchargement d'un modèle de langage (dolphin)">​</a></h2>
<p>Commençons par créer un dossier "models"</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mkdir ./models</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Nous pouvons maintenant télécharger un modèle de langage.</p>
<p>Commençons avec un "petit" modèle de langage, Dolphin, basé sur Mistral dont on peut trouver la description sur HuggingFace <a href="https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF" target="_blank" rel="noopener noreferrer">https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF</a></p>
<p>Sur la page de téléchargement <a href="https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF/tree/main" target="_blank" rel="noopener noreferrer">https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF/tree/main</a>, il existe plusieurs versions Q2, Q3... qui correspondent à la "compression" ou <a href="https://inside-machinelearning.com/quantization-tensorflow/" target="_blank" rel="noopener noreferrer">quantization</a> du modèle</p>
<p>On peut télécharger ce modèle dolphin-2.2.1-mistral-7B-GGUF avec wget</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">!wget -O ./models/dolphin-2.2.1-mistral-7b.Q2_K.gguf https://huggingface.co/TheBloke/dolphin-2.2.1-mistral-7B-GGUF/resolve/main/dolphin-2.2.1-mistral-7b.Q2_K.gguf?download=true</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>C'est la première cellule dans le Google colab et vous pouvez l'executer en cliquant</p>
<p><img decoding="async" loading="lazy" alt="lancement colab" src="https://scenaristeur.github.io/igora/fr/assets/images/lancement_colab-19c0f260e221d998c295f49371beed2e.png" width="884" height="432" class="img_ev3q"></p>
<p>Si tout ce passe bien, vous devriez maintenant voir dans les fichiers locaux de votre colab <a href="https://colab.research.google.com/github/scenaristeur/igora/blob/main/notebooks/llama_cpp_python_fr.ipynb" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="img_ev3q"></a> votre modèle.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-installation-dun-moteur-dinférence-llama-cpp-python">2 Installation d'un moteur d'inférence (llama-cpp-python)<a href="https://scenaristeur.github.io/igora/fr/blog/Pour%20bien%20d%C3%A9marrer%20avec%20les%20LLM%20!#2-installation-dun-moteur-dinf%C3%A9rence-llama-cpp-python" class="hash-link" aria-label="Lien direct vers 2 Installation d'un moteur d'inférence (llama-cpp-python)" title="Lien direct vers 2 Installation d'un moteur d'inférence (llama-cpp-python)">​</a></h2>
<p>Pour le moteur d'inférence, on va utiliser <a href="https://llama-cpp-python.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">llama-cpp-python</a> simplement avec la commande :</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install llama-cpp-python[server] --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Comme précédemment vous pouvez la lancer dans Colab en cliquant sur le triangle correspondant à la cellule.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-interrogation-du-modèle-de-langage-via-le-moteur-dinférence-nomme-les-planètes-du-système-solaire">3 Interrogation du modèle de langage via le moteur d'inférence (Nomme les planètes du système solaire)<a href="https://scenaristeur.github.io/igora/fr/blog/Pour%20bien%20d%C3%A9marrer%20avec%20les%20LLM%20!#3-interrogation-du-mod%C3%A8le-de-langage-via-le-moteur-dinf%C3%A9rence-nomme-les-plan%C3%A8tes-du-syst%C3%A8me-solaire" class="hash-link" aria-label="Lien direct vers 3 Interrogation du modèle de langage via le moteur d'inférence (Nomme les planètes du système solaire)" title="Lien direct vers 3 Interrogation du modèle de langage via le moteur d'inférence (Nomme les planètes du système solaire)">​</a></h2>
<p>La dernière étape est d'implémenter un tout petit code pour</p>
<ul>
<li>importer notre moteur d'inférence(llama-cpp) <code>from llama_cpp import Llama</code></li>
<li>en utilisant ce moteur d'inférence, on créé notre llm</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm = Llama(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      model_path="./models/dolphin-2.2.1-mistral-7b.Q2_K.gguf"</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<ul>
<li>et on interroge notre llm en lui passant la question à laquelle on souhaite qu'il réponde, puis on affiche la réponse</li>
</ul>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">output = llm(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      "Q: (Nomme les planètes du système solaire). A: ", # Prompt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      max_tokens=150, # Generate up to 32 tokens, set to None to generate up to the end of the context window</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      stop=["Q:", "\n"], # Stop generating just before the model would generate a new question</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      echo=True # Echo the prompt back in the output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) # Generate a completion, can also call create_completion</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">print(output)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Le code complet nous donne donc</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">from llama_cpp import Llama</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">llm = Llama(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      model_path="./models/dolphin-2.2.1-mistral-7b.Q2_K.gguf",</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # n_gpu_layers=-1, # Uncomment to use GPU acceleration</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # seed=1337, # Uncomment to set a specific seed</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      # n_ctx=2048, # Uncomment to increase the context window</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">output = llm(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      "Q: (Nomme les planètes du système solaire). A: ", # Prompt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      max_tokens=150, # Generate up to 32 tokens, set to None to generate up to the end of the context window</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      stop=["Q:", "\n"], # Stop generating just before the model would generate a new question</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      echo=True # Echo the prompt back in the output</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">) # Generate a completion, can also call create_completion</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">print(output)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">reponse = output['choices'][0]["text"]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">print("\nRéponse", reponse)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Et le résultat :</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">{'id': 'cmpl-f517be80-5ad2-4955-8535-e4e8863e0358', 'object': 'text_completion', 'created': 1714385686, 'model': './models/dolphin-2.2.1-mistral-7b.Q2_K.gguf', 'choices': [{'text': 'Q: (Nomme les planètes du système solaire). A:  Les planètes du système solaire sont:', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 20, 'completion_tokens': 12, 'total_tokens': 32}}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Réponse Q: (Nomme les planètes du système solaire). A: 1. Mercure 2. Vénus 3. La Terre 4. Mars 5. Jupiter 6. Saturne 7. Uranus 8. Neptune</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Et voilà, vous avez implémenté votre premier LLM et vous pouvez l'utiliser, changer la question...</p>
<p>Evidemment, il existe des tonnes de paramètres, de personnalisation pour leur demander des choses plus précises, orienter votre llm en lui imposant une façon d'agir avec un "prompt système"...</p>]]></content:encoded>
            <category>igora</category>
            <category>llm</category>
            <category>llama-cpp-python</category>
            <category>collab</category>
        </item>
        <item>
            <title><![CDATA[C'est parti !]]></title>
            <link>https://scenaristeur.github.io/igora/fr/blog/c'est parti !</link>
            <guid>https://scenaristeur.github.io/igora/fr/blog/c'est parti !</guid>
            <pubDate>Tue, 05 Mar 2024 00:00:00 GMT</pubDate>
            <description><![CDATA[Ca y est ! La première version du protocole Igora est maintenant disponible !]]></description>
            <content:encoded><![CDATA[<p>Ca y est ! La première version du <em><strong>protocole Igora</strong></em> est maintenant disponible !</p>
<p>Mais qu'est-ce que c'est, le protocole Igora ?</p>]]></content:encoded>
            <category>igora</category>
            <category>llm</category>
            <category>chatGPT</category>
            <category>decentralized</category>
            <category>horde</category>
            <category>crowdsourced</category>
        </item>
        <item>
            <title><![CDATA[Welcome]]></title>
            <link>https://scenaristeur.github.io/igora/fr/blog/welcome</link>
            <guid>https://scenaristeur.github.io/igora/fr/blog/welcome</guid>
            <pubDate>Thu, 26 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Docusaurus blogging features are powered by the blog plugin.]]></description>
            <content:encoded><![CDATA[<p><a href="https://docusaurus.io/docs/blog" target="_blank" rel="noopener noreferrer">Docusaurus blogging features</a> are powered by the <a href="https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog" target="_blank" rel="noopener noreferrer">blog plugin</a>.</p>
<p>Simply add Markdown files (or folders) to the <code>blog</code> directory.</p>
<p>Regular blog authors can be added to <code>authors.yml</code>.</p>
<p>The blog post date can be extracted from filenames, such as:</p>
<ul>
<li><code>2019-05-30-welcome.md</code></li>
<li><code>2019-05-30-welcome/index.md</code></li>
</ul>
<p>A blog post folder can be convenient to co-locate blog post images:</p>
<p><img decoding="async" loading="lazy" alt="Docusaurus Plushie" src="https://scenaristeur.github.io/igora/fr/assets/images/docusaurus-plushie-banner-a60f7593abca1e3eef26a9afa244e4fb.jpeg" width="1500" height="500" class="img_ev3q"></p>
<p>The blog supports tags as well!</p>
<p><strong>And if you don't want a blog</strong>: just delete this directory, and use <code>blog: false</code> in your Docusaurus config.</p>]]></content:encoded>
            <category>facebook</category>
            <category>hello</category>
            <category>docusaurus</category>
        </item>
        <item>
            <title><![CDATA[MDX Blog Post]]></title>
            <link>https://scenaristeur.github.io/igora/fr/blog/mdx-blog-post</link>
            <guid>https://scenaristeur.github.io/igora/fr/blog/mdx-blog-post</guid>
            <pubDate>Sun, 01 Aug 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Blog posts support Docusaurus Markdown features, such as MDX.]]></description>
            <content:encoded><![CDATA[<p>Blog posts support <a href="https://docusaurus.io/docs/markdown-features" target="_blank" rel="noopener noreferrer">Docusaurus Markdown features</a>, such as <a href="https://mdxjs.com/" target="_blank" rel="noopener noreferrer">MDX</a>.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>astuce</div><div class="admonitionContent_BuS1"><p>Use the power of React to create interactive blog posts.</p><div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token operator">&lt;</span><span class="token plain">button onClick</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token arrow operator">=&gt;</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">alert</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">'button clicked!'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token operator">&gt;</span><span class="token maybe-class-name">Click</span><span class="token plain"> me</span><span class="token operator">!</span><span class="token operator">&lt;</span><span class="token operator">/</span><span class="token plain">button</span><span class="token operator">&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copier le code" title="Copier" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><button>Click me!</button></div></div>]]></content:encoded>
            <category>docusaurus</category>
        </item>
        <item>
            <title><![CDATA[Long Blog Post]]></title>
            <link>https://scenaristeur.github.io/igora/fr/blog/long-blog-post</link>
            <guid>https://scenaristeur.github.io/igora/fr/blog/long-blog-post</guid>
            <pubDate>Wed, 29 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[This is the summary of a very long blog post,]]></description>
            <content:encoded><![CDATA[<p>This is the summary of a very long blog post,</p>
<p>Use a <code>&lt;!--</code> <code>truncate</code> <code>--&gt;</code> comment to limit blog post size in the list view.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>
<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>]]></content:encoded>
            <category>hello</category>
            <category>docusaurus</category>
        </item>
        <item>
            <title><![CDATA[First Blog Post]]></title>
            <link>https://scenaristeur.github.io/igora/fr/blog/first-blog-post</link>
            <guid>https://scenaristeur.github.io/igora/fr/blog/first-blog-post</guid>
            <pubDate>Tue, 28 May 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet]]></description>
            <content:encoded><![CDATA[<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet</p>]]></content:encoded>
            <category>hola</category>
            <category>docusaurus</category>
        </item>
    </channel>
</rss>